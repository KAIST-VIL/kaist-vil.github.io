- subject: AI
  data-img-id: img2
  title: Deep Learning Networks to Improve Intelligent Vehicle Assistance Systems for Accident Prevention Using Sensor Data Integration
  fig: research/2.png
  text:
    <h4 style='margin-left:10px; margin-right:10px'>Developing deep learning algorithms using vehicle sensor data is crucial to enhance intelligent vehicle assistance systems' accuracy, adaptability, and real-time decision-making capabilities to provide secure transportation, and prevent any vehicle collision. By developing the improved vision system using multi-modal sensor fusion that generates knowledgeable interpretations of scenes and enables real-time anomaly prediction and obstacle detection, such systems can better navigate diverse road conditions and contribute to autonomous and semi-autonomous vehicles' overall safety and efficiency. </h4>
    <img src="../img/research/2-1.png" class="mini-img"/>
    <h4 style='margin-left:10px; margin-right:10px'>The study improves the road safety and user experience, contributing to more robust, efficient, and reliable systems using active perception in complex and dynamic multi-view driving scenarios. Incorporating pose information into deep learning pipeline helps to focus on significant portions of the image and better understand the spatial context and leverage this information for improved accuracy.</h4>
    <img src="../img/research/2-2.png" class="mini-img"/>

- subject: AI
  data-img-id: img3
  title: Sensing accident-prone features in urban scenes for proactive driving and accident prevention
  fig: research/2.png
  text: <h4 style='margin-left:10px; margin-right:10px'>The fusion of camera and LiDAR sensors is crucial for autonomous vehicles, merging visual cues with 3D mapping to enhance perception and safety. This combination compensates for individual sensor limitations, ensuring accurate environmental interpretation and reliable decision-making in real-time.</h4><img src="../img/research/3-1.png" class="mini-img"/><h4 style='margin-left:10px; margin-right:10px'>This research leverages Vision Transformers to fuse camera and LiDAR data, enhancing autonomous vehicle perception by integrating depth and semantic information. The model employs self-attention to process multi-resolution data, improving environmental understanding and decision-making. Tested in complex scenarios, this method shows improved performance, promising greater safety and efficiency in autonomous driving.</h4><img src="../img/research/3-2.png" class="mini-img"/>

- subject: AI
  data-img-id: img4
  title: Vision Transformers for Enhanced Autonomous Driving Through Multimodal Sensor Fusion
  fig: research/4.png
  text: <h4 style='margin-left:10px; margin-right:10px'>This work proposes an attentive driving system based on visual notifications for proactive accident prevention. Context-specific accident-prone features are identified and drivers are notified of the detected accident-prone features in a proposed head-up display to enhance their decision-making.</h4><img src="../img/research/4-1.png" class="mini-img"/><h4 style='margin-left:10px; margin-right:10px'>Visual information when it pervades along roadways and in roadway traffic can distract drivers in urban cities. In complex driving scenes, drivers are susceptible to accident and may miss important visual cues such as traffic signs and may encounter other accident-prone features. Accident-prone features can be any part of road view image that are highly related to accident phenomena. As an approach to avoid accidents due to missing these visual cues, this work proposes an attentive driving system based on visual notifications.</h4><img src="../img/research/4-2.png" class="mini-img"/>


- subject: AI
  data-img-id: img5
  title: 
  fig:
  text: "<h2 style='font-weight: bold'>Multi-Agent Reinforcement Learning Algorithm</h2> <h4 style='margin-left:10px; margin-right:10px'>Multi-Agent Reinforcement Learning (MARL) is a branch of reinforcement learning (RL) where multiple agents interact within an environment. Unlike traditional RL, MARL involves coordinating and learning policies for multiple agents that may have diverse objectives or conflicting interests. In a multi-agent setting, each agent's actions can influence the environment and, consequently, the experiences of other agents. In MARL, agents typically learn decentralized policies based on their observations, fostering cooperative behavior to collectively achieve shared objectives. Algorithms of centralized training and decentralized execution are attractive ways to obtain such cooperative behavior. </h4><img src='../img/research/5-1.png' class='mini-img' /><h4 style='margin-left:10px; margin-right:10px'> In the domain of heterogeneous (MARL), the emphasis is on encouraging cooperative behavior among diverse agent types. These distinct types encompass entities with unique characteristics, capabilities, or roles within a given environment. Yet, for heterogeneous MARL, conventional centralized training methods pose the difficulty of learning an optimal policy when the individual objectives of each agent type conflict with the shared objective. </h4><img src='../img/research/5-2.png' class='mini-img' /><h4 style='margin-left:10px; margin-right:10px'> To overcome this, we proposed an approach that divides the centralized training process into two stages. In the first training stage, homogeneous agents are grouped and learn their own role-behavior based on rewards related to individual objectives. Subsequently, in the second training stage, all agents are integrated and learn cooperative-behavior from the reward related to the shared objective, facilitating centralized training. To validate the proposed approach, we employed an AI soccer environment characterized by cooperative-competitive and heterogeneous agents. </h4><img src='../img/research/5-3.png' class='mini-img'/><h4 style='margin-left:10px; margin-right:10px'> Additionally, research has been conducted on the development of a learning structure adaptable to a changing environment. In the proposed learning structure, pre-training is conducted in a stable environment, and when a new situation arises, adaptive learning is initiated. An action selector, based on the situation, chooses between the output of the pre-trained model or the adaptively learned model as the final action. To further enhance adaptability, the action selector has been refined to accommodate group-based execution by incorporating heterogeneity in the environment. Subsequent research could advance the sophistication of the action selector by transitioning from a rule-based operation to utilizing neural networks. </h4><br /> <br /><h2 style='font-weight: bold'>Multi-Goal Reinforcement Learning Algorithm</h2> <h4 style='margin-left:10px; margin-right:10px'> Reinforcement Learning (RL) is one of the three main types of machine learning techniques. It involves the learning of policies through the interaction between an agent and its environment. In many real-world scenarios, a single task can have multiple goals simultaneously (e.g. walking to various target places, putting an object in various target spots). The reinforcement learning framework used for training an agent to accomplish multiple objectives concurrently is referred to as Multi-goal RL. The main difference between the RL with a single goal and multi-goal RL is that an agent in multi-goal RL learns a goal-conditioned policy, which takes as inputs a state as well as the goal information. </h4><img src='../img/research/5-4.png' class='mini-img' /><h4 style='margin-left:10px; margin-right:10px'> In multi-goal RL environments with sparse binary rewards, there's a lack of successful experiences in the replay buffer, making agent training challenging. To address this, hindsight experience replay (HER) generates successful experiences, named hindsight experiences, from experiences in the replay buffer. HER generates hindsight experiences from experiences in the replay buffer that contains both unsuccessful and successful ones. However, generating hindsight experiences from successful experiences is less efficient in sampling compared to generating from failed ones. </h4><img src='../img/research/5-5.png' class='mini-img'/><h4 style='margin-left:10px; margin-right:10px'> To address this challenge, we proposed the following hypothesis: what if experiences are sampled in consideration of between achieved goals and failed goals (FGs), where FGs are defined as the original goals that were not successfully attained. Through this research, we aim to substantiate the validity of this hypothesis. Currently, we are conducting the study using a cluster model as a method to consider the property, exploring how it contributes to the effectiveness of the proposed approach. </h4>"


- subject: Energy
  data-img-id: img10
  title: null
  fig: null
  text: "<h2 style='font-weight: bold'>Nanogrid Optimization Technologies for Residential Power Management</h2><h4 style='margin-left:10px; margin-right:10px'>As the decentralized production of energy continues to rise, there is a growing need to facilitate direct trading and sharing of locally generated energy within communities. This enables power grids to effectively integrate distributed energy and facilitates energy exchange among local communities. Furthermore, P2P energy trading offers advantages in terms of stability and reliability over centralized power systems. The introduction of smart grid systems allows for efficient energy transactions between consumers and producers, contributing to the enhancement of energy efficiency. Research in P2P energy trading plays a pivotal role in the evolution of modern power systems and holds promise for future advancements in energy efficiency.</h4><img src='../img/research/12-1.png' class='mini-img' /><h4 style='margin-left:10px; margin-right:10px'> This study presents an approach to the power management of nanogrid clusters assisted by P2P electricity trading. DC nanogrids have lower power loss in real time and are suitable for P2P power trading. For power management of individual clusters, multi-objective optimization is applied. In P2P trading, a cooperative game model is used for buyers and sellers to maximize their welfare. To increase P2P trading efficiency, prediction of load demand and PV power production is considered for power management of each cluster to resolve instantaneous imbalances between load demand and PV power production.</h4><img src='../img/research/12-2.png'  class='mini-img'/><h4 style='margin-left:10px; margin-right:10px'>This study presents a P2P trading strategy for power management of nanogrids with RESs, taking battery lifetime of ESS into consideration. For the power management of a nanogrid, multi-objective optimization is used to minimize grid power consumption, electricity cost, and delay of using electric appliances in appliance scheduling. A battery aging model or degradation cost model is considered in the multi-objective optimization to prolong the ESS lifetime. P2P power trading is carried out based on the cooperative game theory to maximize the welfare of both sellers and buyers.</h4><br />
  <h2 style='font-weight: bold'>Incorporating Energy Storage System into Grid Connected PV System</h2><h4 style='margin-left:10px; margin-right:10px'>This work proposes a new deep learning hybrid gated recurrent unit (GRU) and graph convolutional network (GCN) neural network model, which combines the strengths of the GRU and GCN models, for predicting PV power and electricity load. This model optimally utilizes the PV energy, maximizing FiT revenue streams for the current PV system while also effectively managing the energy stored in the ESS.</h4> <img src='../img/research/10-1.png' class='mini-img'/>"

- subject: Energy
  data-img-id: img12
  title: 
  fig:
  text: "<h2 style='font-weight: bold'> Multi-Vehicle Charging/Discharging Strategies for Industrial Power Management</h2> <h4 style='margin-left:10px; margin-right:10px'> The EV charging/discharging strategy is essential for optimizing the electricity network. The vehicle charging/discharging system efficiently establishes charging infrastructure to meet the rapidly growing demand for electric vehicles, thus supporting the smooth deployment of EVs. Furthermore, an optimized power network enhances the stability of power supply by effectively integrating with the power grid. It also enables the efficient utilization of renewable energy sources. Emphasizing the role of electric vehicles as environmentally friendly modes of transportation, this optimization contributes significantly to promoting sustainable energy usage.</h4><img src='../img/research/13-1.png'  class='mini-img'/>
   <h4 style='margin-left:10px; margin-right:10px'> Researches on EV automatic charging stations for parking towers are being performed, focusing on national living hubs and mobile hubs. The goal is to define standardization and safety criteria for parking tower charging systems, aiming to create a continuous charging living environment based on a strategy for the future proliferation of EVs. This effort contributes to a low-carbon and environmentally friendly society, and proactive measures are taken for carbon neutrality acceleration through the application of renewable energy. Efforts are underway to enhance the efficiency of charging systems for mechanical parking towers. This involves developing an intelligent power grid architecture and conducting power network simulations to optimize energy efficiency. </h4><img src='../img/research/13-2.png'  class='mini-img' /><h4 style='margin-left:10px; margin-right:10px'> For the charging station to take a MG structure, an energy-efficient power management scheme is required for the power provision of EVs while considering the local load demand of the MG. For these purposes, this study presents the power management scheme of interdependent MG and EV fleets aided by a novel EV charging/discharging scheduling algorithm. The maximum amount of discharging power from parked EVs is determined based on the difference between local load demand and PV power production to alleviate imbalances occurred between them. Moreover, a more economical and energy-efficient PV-based charging station is established using the future trends of local load demand and PV power production predicted by a GRU network. </h4>"


- subject: Energy
  data-img-id: img11
  title: 
  fig:
  text: "<h2 style='font-weight: bold'>Management of Distributed Renewable Energy Resources with the Help of Wireless Sensor Network</h2> <h4 style='margin-left:10px; margin-right:10px'>This study proposed kernel recursive least-squares (KRLS) algorithm for predicting PV and wind energy. A wireless sensor network (WSN) was typically adopted for data collection with flexible configuration of sensor nodes. For efficient transmission of the data production, a link scheduling technique based on sensor node attributes was proposed. Different statistical and machine learning (ML) techniques are examined with respect to the proposed KRLS algorithm for performance analysis. </h4><img src='../img/research/10-2.png'  class='mini-img'/>"
